{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQWiz9Afagn8"
   },
   "outputs": [],
   "source": [
    "# Colab library to upload files to notebook\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHFnkiIDajzQ"
   },
   "outputs": [],
   "source": [
    "# Install Kaggle library\n",
    "!pip install -q kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JJRj1Dbdxo8"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/root/.kaggle/kaggle.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-486f77a6e585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle/kaggle.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/.kaggle/kaggle.json'"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!touch ~/.kaggle/kaggle.json\n",
    "\n",
    "api_token = {\"username\":\"UserName\",\"key\":\"UserKey\"} # this is your kaggle api key\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Y3EBhjsMglYO",
    "outputId": "fa694051-3c21-4a53-c54b-c88117e0a173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading amazonreviews.zip to /content\n",
      " 99% 489M/493M [00:04<00:00, 130MB/s]\n",
      "100% 493M/493M [00:04<00:00, 128MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d bittlingmayer/amazonreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFDZEVKA47WL"
   },
   "outputs": [],
   "source": [
    "!mkdir data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lTvhj2GLhWGa",
    "outputId": "18f9590c-6aef-4b0b-a777-ba2c3fcbc6a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  amazonreviews.zip\n",
      "  inflating: data_set/test.ft.txt.bz2  \n",
      "  inflating: data_set/train.ft.txt.bz2  \n"
     ]
    }
   ],
   "source": [
    "!unzip amazonreviews.zip -d data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EWIi-mSmeqZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import bz2\n",
    "import gc\n",
    "import chardet\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pt1eKvQWjWJD"
   },
   "outputs": [],
   "source": [
    "#train_file = bz2.BZ2File('data_set/train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('data_set/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3PIKA3vmW7X"
   },
   "outputs": [],
   "source": [
    "#train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9naDDecmlsp"
   },
   "outputs": [],
   "source": [
    "del test_file #,train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUuGDu4gnEzI"
   },
   "outputs": [],
   "source": [
    "#train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yyc1BLHFnI7X"
   },
   "outputs": [],
   "source": [
    "#train_labels = ['neg' if x.split(' ')[0] == '__label__1' else 'pos' for x in train_file_lines]\n",
    "#train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekmlpLbso2F8"
   },
   "outputs": [],
   "source": [
    "test_labels = ['neg' if x.split(' ')[0] == '__label__1' else 'pos' for x in test_file_lines]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxpJY0ZbnVXU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PQNxc8Onol1"
   },
   "outputs": [],
   "source": [
    "#df_train = pd.DataFrame({'text':train_sentences,'label':train_labels}, columns=['text','label'])\n",
    "df_test = pd.DataFrame({'text':test_sentences,'label':test_labels}, columns=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KA07_2j9oHdr",
    "outputId": "a32e1848-7fee-4926-febd-94af280ae6e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cd: my lovely pat has one of the great v...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one of the best game music soundtracks - for a...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batteries died within a year ...: i bought thi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but maha energy is better: check o...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  great cd: my lovely pat has one of the great v...   pos\n",
       "1  one of the best game music soundtracks - for a...   pos\n",
       "2  batteries died within a year ...: i bought thi...   neg\n",
       "3  works fine, but maha energy is better: check o...   pos\n",
       "4  great for the non-audiophile: reviewed quite a...   pos"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FHH_dsH_oMFf",
    "outputId": "6d1af1a1-cafb-4491-f16a-e32fb4a58ee5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "kE9G6zyJojF_",
    "outputId": "ab78d86b-8438-41b0-d2b6-ace7c5e04a6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f8606a1ad30>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x='label', kind='count', data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2jahlBQor92"
   },
   "outputs": [],
   "source": [
    "#df_train.to_csv('data_set/train.csv', index=False)\n",
    "df_test.to_csv('data_set/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_AHzuYLwHh6",
    "outputId": "fb1e3905-2d0a-4fb5-f701-b9363280f3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  test.csv  test.ft.txt.bz2  train.ft.txt.bz2\n"
     ]
    }
   ],
   "source": [
    "!ls -a data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT8MBb8BpemO"
   },
   "outputs": [],
   "source": [
    "del df_test #, df_train\n",
    "#del train_labels, train_sentences\n",
    "del test_labels, test_sentences\n",
    "#del train_file_lines, test_file_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZ73o8lbqsu-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data, datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbnVyDY-txHo"
   },
   "outputs": [],
   "source": [
    "SEED = 1234 \n",
    "torch.manual_seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy') \n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mp2nAklGtyH2"
   },
   "outputs": [],
   "source": [
    "fields = [('text', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_hXaBEivDSU"
   },
   "outputs": [],
   "source": [
    "train_data = data.TabularDataset(\n",
    "                                        path = 'data_set/test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FT_PAytmxtZw",
    "outputId": "47b2eecd-ebeb-4aed-dc34-6aefc8e6d10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 400000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "#print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xrCPuuNBxuOz",
    "outputId": "7e7a713a-d9c5-4428-c728-7ddec8a4e3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['great', 'cd', ':', 'my', 'lovely', 'pat', 'has', 'one', 'of', 'the', 'great', 'voices', 'of', 'her', 'generation', '.', 'i', 'have', 'listened', 'to', 'this', 'cd', 'for', 'years', 'and', 'i', 'still', 'love', 'it', '.', 'when', 'i', \"'m\", 'in', 'a', 'good', 'mood', 'it', 'makes', 'me', 'feel', 'better', '.', 'a', 'bad', 'mood', 'just', 'evaporates', 'like', 'sugar', 'in', 'the', 'rain', '.', 'this', 'cd', 'just', 'oozes', 'life', '.', 'vocals', 'are', 'jusat', 'stuunning', 'and', 'lyrics', 'just', 'kill', '.', 'one', 'of', 'life', \"'s\", 'hidden', 'gems', '.', 'this', 'is', 'a', 'desert', 'isle', 'cd', 'in', 'my', 'book', '.', 'why', 'she', 'never', 'made', 'it', 'big', 'is', 'just', 'beyond', 'me', '.', 'everytime', 'i', 'play', 'this', ',', 'no', 'matter', 'black', ',', 'white', ',', 'young', ',', 'old', ',', 'male', ',', 'female', 'everybody', 'says', 'one', 'thing', '\"', 'who', 'was', 'that', 'singing', '?', '\"'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWBOWvfJxw8m"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data= train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK2Hr5i-AtVx"
   },
   "outputs": [],
   "source": [
    "valid_data, test_data = valid_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PIjs0bzgx3Lk",
    "outputId": "a5ebe6df-62bc-4f49-b5fb-b4bf6be766f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 280000\n",
      "Number of validation examples: 84000\n",
      "Number of testing examples: 36000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wyZ0Kbu8x6na",
    "outputId": "93d6f7be-86d2-4744-cab8-965f751a52fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                          \n",
      "100%|█████████▉| 399229/400000 [00:27<00:00, 14764.36it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 100000\n",
    "\n",
    "# build the vocabulary on our datas\n",
    "#TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "\n",
    "\n",
    "# use this one if want to use better embedding method it uses glove\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.200d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9PGzffTGx9RB",
    "outputId": "7ae451e7-f36d-4dc3-b0ed-1ea017a51d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 100002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QXlW7bK9x_7i",
    "outputId": "4c469ceb-08c8-4fc9-c527-e9757827404d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f85ba383bf8>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "# print all the labels\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "2SLg0s04yCiQ",
    "outputId": "3dc5041c-b0ff-417b-c7ef-b5b226e84a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 1154137), ('the', 1103728), (',', 795017), ('i', 627125), ('and', 598144), ('a', 558247), ('to', 536433), ('it', 495415), ('of', 441118), ('this', 405913), ('is', 394383), (':', 302786), ('in', 257578), ('for', 246061), ('!', 230782), ('that', 225025), ('was', 194573), ('you', 192227), ('not', 186662), ('\"', 182002)]\n"
     ]
    }
   ],
   "source": [
    "# print 20 most common text vocabulary\n",
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM2QhEDdyE7Q"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort=False,\n",
    "    #sort_key = lambda x: len(x.comment_text),\n",
    "\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkNtPdEgyMaT"
   },
   "outputs": [],
   "source": [
    "# create the model \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # torch.permute is use to swap the axis\n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ChciCztSyNcY",
    "outputId": "331a9868-ca24-41bf-a498-4a1d91cc91bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_DIM: 100002 \n",
      "EMBEDDING_DIM: 200 \n",
      "N_FILTERS: 100 \n",
      "FILTER_SIZES: [2, 3, 4] \n",
      "OUTPUT_DIM: 1 \n",
      "PAD_IDX: 1\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 1 # for just binary classification\n",
    "# OUTPUT_DIM = len(LABEL.vocab) # for multiclass classification uncomment this\n",
    "DROPOUT = 0.3\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "print('INPUT_DIM:',INPUT_DIM,\"\\nEMBEDDING_DIM:\",EMBEDDING_DIM,\"\\nN_FILTERS:\",N_FILTERS,\"\\nFILTER_SIZES:\",FILTER_SIZES,\"\\nOUTPUT_DIM:\",OUTPUT_DIM,\"\\nPAD_IDX:\",PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BXzUxL1EySKC",
    "outputId": "fad769aa-1d0a-41b4-e4fb-7ecc5476ded5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi[TEXT.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KJTOyDA1yUjO",
    "outputId": "84fca218-f8ef-4c16-9ca9-0e060bfa40d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,181,001 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "k2gNuqN1yXEm",
    "outputId": "dc746aca-740b-48ae-8d6a-38259a559ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.8542,  0.4022,  0.4238],\n",
      "        [ 0.2078,  1.1879, -0.7320,  ...,  1.3663, -0.4598,  0.6668],\n",
      "        [ 0.1229,  0.5804, -0.0696,  ..., -0.0392, -0.1624, -0.0967],\n",
      "        ...,\n",
      "        [ 0.1589, -0.4828,  0.2063,  ...,  0.3581, -0.3142, -0.2211],\n",
      "        [ 0.4979,  1.2720, -2.0297,  ...,  0.4564, -0.1406, -1.9060],\n",
      "        [ 0.0905, -0.4785,  0.1473,  ...,  0.4376,  1.3531,  0.2133]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.8542,  0.4022,  0.4238],\n",
       "        [ 0.2078,  1.1879, -0.7320,  ...,  1.3663, -0.4598,  0.6668],\n",
       "        [ 0.1229,  0.5804, -0.0696,  ..., -0.0392, -0.1624, -0.0967],\n",
       "        ...,\n",
       "        [ 0.1589, -0.4828,  0.2063,  ...,  0.3581, -0.3142, -0.2211],\n",
       "        [ 0.4979,  1.2720, -2.0297,  ...,  0.4564, -0.1406, -1.9060],\n",
       "        [ 0.0905, -0.4785,  0.1473,  ...,  0.4376,  1.3531,  0.2133]])"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTQH3sqiyZw7"
   },
   "outputs": [],
   "source": [
    "#Then zero the initial weights of the unknown and padding tokens.\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSY_0k7PycS2"
   },
   "outputs": [],
   "source": [
    "#weight_decay=0.01\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.00001)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss() #for multi-class uncomment this\n",
    "criterion = nn.BCEWithLogitsLoss() # for two class\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PY2uMjvyhAl"
   },
   "outputs": [],
   "source": [
    "# use for two class classification\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzFYmnCsyjoY"
   },
   "outputs": [],
   "source": [
    "# use for multiple class classification\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qhwCp9aynCM"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label) # for binary class\n",
    "        #acc = categorical_accuracy(predictions, batch.label) # for multiclass uncomment this\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66dWK1yOyraJ"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label) # for two class\n",
    "            #acc = categorical_accuracy(predictions, batch.label) # for mlticlass uncomment this\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJjdbILzyuKv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1l7LZNOCqoCS"
   },
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "d8QVgOOGywpX",
    "outputId": "6242b9c2-9370-4fb3-9042-210f1c25f738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 43s\n",
      "\tTrain Loss: 0.134 | Train Acc: 95.10%\n",
      "\t Val. Loss: 0.185 |  Val. Acc: 92.93%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut5-model2.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FTypYfdiyzsK",
    "outputId": "5b9b7b73-029e-4ba4-df8c-c28b099ca69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.190 | Test Acc: 93.18%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut5-model2.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qeDrctry2b8"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_class(model, sentence, min_len = 4):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = torch.sigmoid(model(tensor))\n",
    "    #max_preds = preds.argmax(dim = 1) # for multiclass\n",
    "    return preds[0][0]#round(float(preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8zXkiddKy8w_",
    "outputId": "8044c945-7f32-4e86-fbcf-471ebe7392cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1273, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class(model, \"You look at this laptop and think nah it's not that great looking no way I can play 144hz gameplay on this but when you look at the specifications you get blown away. Rtx2080 with Intel i9 processor and on top of that 144hz display panel. Only down side with this machine is it's speakers and design. Apart from that, on performance it's a beast. I would totally recommend it for gaming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7izLwEPOzCyS",
    "outputId": "4f530fbd-988c-4b32-c2a1-96892d61d903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is: 1 = pos\n"
     ]
    }
   ],
   "source": [
    "pred_class = round(float(predict_class(model, \"Only down side with this machine is it's speakers and design. Apart from that, on performance it's a beast. I would totally recommend it if you are not into aesthetics that much.\")))\n",
    "print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaWcUKxe1FAC"
   },
   "outputs": [],
   "source": [
    "torch.save(TEXT.vocab,'vocab.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJ0h7FIS1OwN"
   },
   "outputs": [],
   "source": [
    "torch.save(LABEL.vocab, 'label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CV_aKG1J1SAQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "amazon-sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
